# EECE5644 Machine Learning and Pattern Recognition 

## Projects:

### Assignment 1:

**Q1:** Part A: ERM classification using the knowledge of true data pdf. Part B: ERM classification attempt using incorrect knowledge of data distribution. Part C: Fisher Linear Discriminant Analysis (LDA) based classifier.

**Q2:** Part A: Minimum probability of error classification (0-1 loss, MAP classification rule). Part B: ERM classification rule with the Different loss values for each class.

[PDF Report](Assignment1/Assignment1_Juan_Bernal.pdf)

### Assignment 2:

**Q1:** Part A: Determined the theoretically optimal classifier that achieves minimum probability of error using the knowledge of the true pdf. Part B: Using the maximum likelihood parameter estimation technique, estimated the class priors and class conditional pdfs and class priors. Part C: Using the maximum likelihood parameter estimation technique trained three separate logistic-linear-function-based approximations of class label posterior functions using datasets containing 50, 500, and 5000 samples.

**Q2:** Used the BIC method in an order selection exercise to find the correct number of Gaussians the GMM training data contained.

[PDF Report](Assignment2/Assignment2_Juan_Bernal.pdf)

### Assignment 3:

**Q1:** Trained many multilayer perceptrons (MLP) to approximate the class
label posteriors, using maximum likelihood parameter estimation (equivalently, with minimum
average cross-entropy loss) to train the MLP.


**Q2:** Derived the solution for ridge regression in the case of a linear model with additive white
Gaussian noise corrupting both input and output data. Then implemented it and select the
hyper parameter (prior parameter) with cross-validation.

[PDF Report](Assignment3/Assignment3_Juan_Bernal.pdf)

### Assignment 4:

**Q1:** Trained a single hidden layer MLP with softplus activation functions in the first layer to approximate the y values with x
values as input to the model neural network (Assuming that y = f(x) + N(0,σ^2)). Used 10-fold cross-validation to select the best number
of perceptrons in the first layer.

**Q2:** Trained and evaluated a support vector machine classifier with a Gaussian kernel (radial-basis function (RBF) kernel). Used 10-fold
cross-validation to select the best box constraint hyperparameter C and the Gaussian kernel width parameter σ.

**Q3:** Used GMM-based clustering to segment color images.

[PDF Report](Assignment4/Assignment4_Juan_Bernal.pdf)

**----------------------------------------------------------------------------------------------------**

Please refer to the PDF Reports for a detailed explanation of the methods and results of each project.
